{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 628563,
          "datasetId": 116400,
          "databundleVersionId": 647738,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "!pip install -q git+https://github.com/MostafaShams5/NeuroMend.git\n!pip install -q --upgrade torch torchvision torchaudio\n!pip install -q diffusers transformers==4.41.2 accelerate bitsandbytes\n!pip install -q umap-learn hdbscan matplotlib seaborn opencv-python\n!pip install -q ultralytics qwen-vl-utils kagglehub\n\nimport shutil\nimport os\nfor path in [\"/kaggle/working/neuromend_output\", \"/kaggle/working/experiment_data\", \"/kaggle/working/raw_data\"]:\n    if os.path.exists(path): shutil.rmtree(path)",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport os\nfrom transformers import AutoProcessor, AutoModelForCausalLM\n\nclass NeuroMendEngine:\n    def __init__(self, device=\"cuda\"):\n        self.device = device\n        self.model = AutoModelForCausalLM.from_pretrained(\n            \"microsoft/Florence-2-large\", \n            trust_remote_code=True,\n            attn_implementation=\"eager\", \n            torch_dtype=torch.float16\n        ).to(self.device).eval()\n        self.processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\", trust_remote_code=True)\n\n    def label_dataset(self, image_paths, target_class, output_dir):\n        os.makedirs(output_dir, exist_ok=True)\n        task_prompt = \"<CAPTION_TO_PHRASE_GROUNDING>\"\n        text_input = f\"{task_prompt} {target_class}\"\n        \n        for img_path in tqdm(image_paths):\n            try:\n                self._process_single_label(img_path, text_input, task_prompt, output_dir)\n            except: pass\n\n    def _process_single_label(self, img_path, text_input, task_prompt, output_dir):\n        image = Image.open(img_path).convert(\"RGB\")\n        inputs = self.processor(text=text_input, images=image, return_tensors=\"pt\").to(self.device, torch.float16)\n        with torch.no_grad():\n            generated_ids = self.model.generate(\n                input_ids=inputs[\"input_ids\"], pixel_values=inputs[\"pixel_values\"],\n                max_new_tokens=1024, num_beams=1, do_sample=False, use_cache=False\n            )\n        generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n        prediction = self.processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n        \n        bboxes = prediction[task_prompt]['bboxes']\n        if not bboxes: return\n\n        yolo_lines = []\n        for box in bboxes:\n            x1, y1, x2, y2 = box\n            w, h = x2 - x1, y2 - y1\n            xc, yc = x1 + w/2, y1 + h/2\n            yolo_lines.append(f\"0 {xc/image.width:.6f} {yc/image.height:.6f} {w/image.width:.6f} {h/image.height:.6f}\")\n        \n        with open(os.path.join(output_dir, os.path.basename(img_path).replace(\".jpg\", \".txt\")), \"w\") as f:\n            f.write(\"\\n\".join(yolo_lines))\n\n    def diagnose(self, image_path):\n        task_prompt = \"<DETAILED_CAPTION>\"\n        image = Image.open(image_path).convert(\"RGB\")\n        inputs = self.processor(text=task_prompt, images=image, return_tensors=\"pt\").to(self.device, torch.float16)\n        \n        with torch.no_grad():\n            generated_ids = self.model.generate(\n                input_ids=inputs[\"input_ids\"], pixel_values=inputs[\"pixel_values\"],\n                max_new_tokens=100, num_beams=1, do_sample=False, use_cache=False\n            )\n        caption = self.processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n        \n        diagnosis = []\n        caption_lower = caption.lower()\n        if \"dark\" in caption_lower or \"night\" in caption_lower or \"shadow\" in caption_lower: diagnosis.append(\"low light\")\n        if \"blur\" in caption_lower or \"grainy\" in caption_lower: diagnosis.append(\"motion blur\")\n        if \"rain\" in caption_lower or \"wet\" in caption_lower: diagnosis.append(\"rainy\")\n        \n        return \", \".join(diagnosis) if diagnosis else \"low visibility\"\n\ndef flush():\n    import gc\n    gc.collect()\n    torch.cuda.empty_cache()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import kagglehub\nimport cv2\nimport numpy as np\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\nimport shutil\nimport os\n\nRAW_DIR = \"/kaggle/working/raw_data\"\nEXP_DIR = \"/kaggle/working/experiment_data\"\nif os.path.exists(RAW_DIR): shutil.rmtree(RAW_DIR)\nif os.path.exists(EXP_DIR): shutil.rmtree(EXP_DIR)\nos.makedirs(RAW_DIR, exist_ok=True)\n\nds_path = kagglehub.dataset_download(\"sachinpatel21/pothole-image-dataset\")\nsrc_images = [y for x in os.walk(ds_path) for y in glob(os.path.join(x[0], '*.jpg'))][:300]\n\nall_images = []\nfor i, src in enumerate(src_images):\n    try:\n        img = cv2.imread(src)\n        if img is not None:\n            dst = f\"{RAW_DIR}/pothole_{i}.jpg\"\n            cv2.imwrite(dst, img)\n            all_images.append(dst)\n    except: pass\n\ntrain_imgs, test_imgs = train_test_split(all_images, test_size=0.3, random_state=42)\n\ntrain_dir = f\"{EXP_DIR}/train_clean\"\nos.makedirs(train_dir, exist_ok=True)\nfor p in train_imgs: shutil.copy(p, f\"{train_dir}/{os.path.basename(p)}\")\n\ntest_dir = f\"{EXP_DIR}/test_hard\"\nos.makedirs(test_dir, exist_ok=True)\n\nfor p in test_imgs:\n    img = cv2.imread(p)\n    \n    size = 20 \n    kernel = np.zeros((size, size))\n    kernel[int((size-1)/2), :] = np.ones(size) / size\n    blur = cv2.filter2D(img, -1, kernel)\n    \n    noise = np.random.normal(0, 25, blur.shape).astype(np.uint8)\n    noisy = cv2.add(blur, noise)\n    \n    final = (noisy * 0.6).astype(np.uint8)\n    \n    cv2.imwrite(f\"{test_dir}/{os.path.basename(p)}\", final)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "labeler = NeuroMendEngine()\nlabeler.label_dataset([f\"{train_dir}/{x}\" for x in os.listdir(train_dir)], \"pothole\", train_dir)\nlabeler.label_dataset([f\"{test_dir}/{x}\" for x in os.listdir(test_dir)], \"pothole\", test_dir)\ndel labeler\nflush()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from ultralytics import YOLO\n\nCFG_DIR = \"/kaggle/working/yolo_cfg\"\nfor s in ['train', 'val']:\n    os.makedirs(f\"{CFG_DIR}/{s}/images\", exist_ok=True)\n    os.makedirs(f\"{CFG_DIR}/{s}/labels\", exist_ok=True)\n\ndef copy_data(src, split):\n    for f in os.listdir(src):\n        if f.endswith(\".jpg\"): shutil.copy(f\"{src}/{f}\", f\"{CFG_DIR}/{split}/images/{f}\")\n        if f.endswith(\".txt\"): shutil.copy(f\"{src}/{f}\", f\"{CFG_DIR}/{split}/labels/{f}\")\n\ncopy_data(train_dir, \"train\")\ncopy_data(test_dir, \"val\")\n\nwith open(f\"{CFG_DIR}/data.yaml\", \"w\") as f:\n    f.write(f\"path: {CFG_DIR}\\ntrain: train/images\\nval: val/images\\nnc: 1\\nnames: ['pothole']\")\n\nmodel_a = YOLO(\"yolov8n.pt\") \nres_a = model_a.train(data=f\"{CFG_DIR}/data.yaml\", epochs=8, imgsz=512, verbose=False, project=\"/kaggle/working/runs\", name=\"base\")\nmap_a = res_a.box.map50",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from neuro_mend import Generator\n\nengine = NeuroMendEngine()\n\nsample_fail = glob(f\"{test_dir}/*.jpg\")[0]\ndiagnosis = engine.diagnose(sample_fail)\n\ngenerator = Generator()\nsynth_out = \"/kaggle/working/neuromend_fix\"\nprompt = f\"pothole on road, {diagnosis}, motion blur, night, low quality, dashboard camera\"\n\nclean_sources = glob(f\"{train_dir}/*.jpg\")\ngenerator.synthesize(clean_sources, prompt, synth_out, count=60)\ndel generator\nflush()\n\nengine.label_dataset(glob(f\"{synth_out}/*.jpg\"), \"pothole\", synth_out)\ndel engine\nflush()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "for f in os.listdir(synth_out):\n    if f.endswith(\".jpg\"): shutil.copy(f\"{synth_out}/{f}\", f\"{CFG_DIR}/train/images/syn_{f}\")\n    if f.endswith(\".txt\"): shutil.copy(f\"{synth_out}/{f}\", f\"{CFG_DIR}/train/labels/syn_{f}\")\n\nmodel_b = YOLO(\"yolov8n.pt\")\nres_b = model_b.train(data=f\"{CFG_DIR}/data.yaml\", epochs=8, imgsz=512, verbose=False, project=\"/kaggle/working/runs\", name=\"patch\")\nmap_b = res_b.box.map50",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\nimp = ((map_b - map_a) / map_a * 100) if map_a > 0.01 else 0\n\nplt.figure(figsize=(6,5))\nplt.bar([\"Baseline\", \"Neuro-Mend\"], [map_a, map_b], color=['#e74c3c', '#2ecc71'])\nplt.title(f\"Performance on Hard Edge Cases (Blur/Rain)\\nImprovement: +{imp:.0f}%\")\nplt.ylabel(\"mAP@50 Accuracy\")\nplt.ylim(0, 1.0)\nplt.grid(axis='y', alpha=0.3)\nplt.savefig(\"final_result.png\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
